{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda, Conv2D, MaxPooling2D, Flatten, BatchNormalization, concatenate, Activation, Subtract, merge, Reshape, UpSampling2D\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "stickyPath = \"../dataset/seen-dataset/TrainingSet/\"\n",
    "onlyfiles = [f for f in listdir(stickyPath) if isfile(join(stickyPath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = onlyfiles[0:int(len(onlyfiles)*0.9)]\n",
    "valData = onlyfiles[int(len(onlyfiles)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGen(batchSize,_data,vis=False):\n",
    "    idx = 0\n",
    "    hshift = (-64,64)\n",
    "    vshift = (-64,64)\n",
    "    while(True):\n",
    "        rows = np.random.randint(0,len(_data),batchSize)\n",
    "        data = []\n",
    "        for image in rows:\n",
    "            data.append(_data[image])\n",
    "        returnInput=[]\n",
    "        for image in data:\n",
    "            skeleton = []\n",
    "            left = cv2.imread(str(stickyPath+image),cv2.IMREAD_GRAYSCALE)\n",
    "            #right = data.iloc[row,1]\n",
    "            #right = cv2.imread(str(\"../dataset/seen-dataset/TrainingSet/\"+right),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Floating Point\n",
    "            leftImage = left.astype('float32')\n",
    "            leftImage /= 255\n",
    "            leftImage = 1 - leftImage\n",
    "            #rightImage = right.astype('float32')\n",
    "            #rightImage /= 255\n",
    "            \n",
    "            temp=[leftImage]\n",
    "            \n",
    "            skeleton.append(temp)\n",
    "            \n",
    "            # Shifting\n",
    "            randH = np.random.randint(hshift[0],hshift[1])\n",
    "            randV = np.random.randint(vshift[0],vshift[1])\n",
    "            \n",
    "            leftImageShiftedH=np.roll(axis=0,a=leftImage,shift=randH)\n",
    "            #rightImageShiftedH=np.roll(axis=0,a=rightImage,shift=randH)\n",
    "            \n",
    "            leftImageShiftedV=np.roll(axis=0,a=leftImage,shift=randV)\n",
    "            #rightImageShiftedV=np.roll(axis=0,a=rightImage,shift=randV)\n",
    "            \n",
    "            temp = [leftImageShiftedV]\n",
    "            skeleton.append(temp)\n",
    "            temp = [leftImageShiftedH]\n",
    "            skeleton.append(temp)\n",
    "            returnInput.append(skeleton)     \n",
    "        returnInput = np.array(returnInput)\n",
    "        returnInput = returnInput.reshape(batchSize*3,64,64)\n",
    "        \n",
    "        blank =[]\n",
    "        \n",
    "        blank.append(returnInput)\n",
    "        \n",
    "        returnInput = np.array(blank)\n",
    "        \n",
    "        returnInput = np.moveaxis(returnInput,0,3)\n",
    "        \n",
    "        if(vis):\n",
    "            print(returnInput)\n",
    "        \n",
    "        yield [returnInput,returnInput]\n",
    "        \n",
    "def valGen(_data,vis=False):\n",
    "    idx = 0\n",
    "    while(True):\n",
    "        rows = np.random.randint(0,len(_data),len(_data))\n",
    "        data = []\n",
    "        for image in rows:\n",
    "            data.append(_data[image])\n",
    "        returnInput=[]\n",
    "        for image in data:\n",
    "            skeleton = []\n",
    "            left = cv2.imread(str(stickyPath+image),cv2.IMREAD_GRAYSCALE)\n",
    "            #right = data.iloc[row,1]\n",
    "            #right = cv2.imread(str(\"../dataset/seen-dataset/TrainingSet/\"+right),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Floating Point\n",
    "            leftImage = left.astype('float32')\n",
    "            leftImage /= 255\n",
    "            leftImage = 1 - leftImage\n",
    "            #rightImage = right.astype('float32')\n",
    "            #rightImage /= 255\n",
    "            \n",
    "            temp=[leftImage]\n",
    "            \n",
    "            skeleton.append(temp)\n",
    "            \n",
    "            returnInput.append(skeleton)     \n",
    "        returnInput = np.array(returnInput)\n",
    "        returnInput = returnInput.reshape(len(_data),64,64)\n",
    "        \n",
    "        blank =[]\n",
    "        \n",
    "        blank.append(returnInput)\n",
    "        \n",
    "        returnInput = np.array(blank)\n",
    "        \n",
    "        returnInput = np.moveaxis(returnInput,0,3)\n",
    "        \n",
    "        if(vis):\n",
    "            print(returnInput)\n",
    "        \n",
    "        yield [returnInput,returnInput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineDist(vects):\n",
    "    x, y = vects\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cosineDist_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aml/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(64, 64, 1))  # adapt this if using `channels_first` image data format\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = Flatten()(x)\n",
    "encoded = Dense(8*8*8, activation='relu', name='latent')(encoded)\n",
    "# model = Model(input_img,encoded)\n",
    "# print(model.summary())\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "r = Reshape(target_shape=(8,8,8))(encoded)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(r)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "#x = BatchNormalization()(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same',name='output')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='RMSprop', loss='binary_crossentropy')\n",
    "\n",
    "#display(SVG(model_to_dot(autoencoder, show_layer_names=True, show_shapes=True, rankdir='TB').create(prog='dot', format='svg')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainGenObj = trainGen(batchSize,_data=trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valGenObj = valGen(_data=valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(valGenObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][1,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1285, 64, 64, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in range(len(test)):\n",
    "    plt.imshow(test[image,:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './log/ae/seen'\n",
    "runIter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1386/1386 [==============================] - 31s 22ms/step - loss: 0.0702 - val_loss: 0.0683\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06830, saving model to weights/simple_ae_maxpool_Seen_weights_v1.h5\n",
      "Epoch 2/500\n",
      "1386/1386 [==============================] - 30s 22ms/step - loss: 0.0697 - val_loss: 0.0655\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06830 to 0.06554, saving model to weights/simple_ae_maxpool_Seen_weights_v1.h5\n",
      "Epoch 3/500\n",
      " 788/1386 [================>.............] - ETA: 13s - loss: 0.0697"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8a6725a31c4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtbCallBack\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aml/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc = ModelCheckpoint(filepath='weights/simple_ae_maxpool_Seen_weights_v1.h5', \n",
    "                     monitor='val_loss',period=1,save_best_only=True,\n",
    "                     save_weights_only=True,mode='auto',verbose=1)\n",
    "es = EarlyStopping(patience=250, monitor='val_loss', min_delta=0.0005, mode='auto')\n",
    "tbCallBack = TensorBoard(log_dir=str('./log/seen/ae/run'+str(runIter)), histogram_freq=0,\n",
    "                         write_graph=True,\n",
    "                         write_grads=True,\n",
    "                         batch_size=batchSize,\n",
    "                         write_images=True)\n",
    "runIter +=1\n",
    "autoencoder.fit_generator(\n",
    "    trainGenObj,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    validation_data=valGenObj,\n",
    "    validation_steps=1,\n",
    "    steps_per_epoch=((len(trainData)//batchSize)*3),\n",
    "    callbacks=[mc,es,tbCallBack]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = [test[0][7,:,:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.moveaxis(image,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_input = [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = autoencoder.predict([_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test[0][7,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test2[0,:,:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
